{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6edde495",
   "metadata": {},
   "source": [
    "Foundations of AI - Real world Activity! \n",
    "\n",
    "Scenario: Smart Vacuum Robot in a 2D room (grid).\n",
    "Agent type implemented: MODEL-BASED AGENT.\n",
    "\n",
    "Goal: Clean all dirty tiles with minimum steps (\"energy\").\n",
    "The agent only senses the CURRENT tile (dirty/clean) and the room boundaries.\n",
    "It maintains an internal map (model) of what it has seen so far.\n",
    "\n",
    "Your task (Optimization):\n",
    "1) Improve the agent’s decision policy to reduce steps/energy.\n",
    "2) Keep the same environment + sensing limits.\n",
    "3) Compare baseline vs your optimized agent over multiple random rooms.\n",
    "\n",
    "Hint ideas:\n",
    "- Systematic exploration instead of random moves when stuck.\n",
    "- Remember “frontier” (unknown tiles adjacent to known tiles) and navigate there.\n",
    "- If you have seen any dirty tile, plan a shortest path to it (BFS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eba9870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Baseline Model-Based Reflex Agent ===\n",
      "Trials: 30, Grid: 8x8, DirtProb: 0.3\n",
      "Success (cleaned all within max_steps): 30/30\n",
      "Avg steps: 167.4   Median steps: 120.0   Min/Max: 94/387\n",
      "\n",
      "Your optimization target: reduce Avg steps and/or increase success rate.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Tuple\n",
    "import random\n",
    "import statistics\n",
    "\n",
    "Pos = Tuple[int, int]  # (row, col)\n",
    "\n",
    "@dataclass\n",
    "class Room:\n",
    "    rows: int\n",
    "    cols: int\n",
    "    dirt_prob: float = 0.25\n",
    "    seed: int = 0\n",
    "\n",
    "    def __post_init__(self):\n",
    "        rnd = random.Random(self.seed)\n",
    "        # True = dirty, False = clean\n",
    "        self.grid = [[(rnd.random() < self.dirt_prob) for _ in range(self.cols)] for _ in range(self.rows)]\n",
    "\n",
    "    def is_dirty(self, p: Pos) -> bool:\n",
    "        r, c = p\n",
    "        return self.grid[r][c]\n",
    "\n",
    "    def clean(self, p: Pos) -> None:\n",
    "        r, c = p\n",
    "        self.grid[r][c] = False\n",
    "\n",
    "    def dirt_count(self) -> int:\n",
    "        return sum(1 for r in range(self.rows) for c in range(self.cols) if self.grid[r][c])\n",
    "\n",
    "@dataclass\n",
    "class Percept:\n",
    "    pos: Pos\n",
    "    dirty_here: bool\n",
    "    # Boundary sensors (agent knows if a move would hit a wall)\n",
    "    wall_up: bool\n",
    "    wall_down: bool\n",
    "    wall_left: bool\n",
    "    wall_right: bool\n",
    "\n",
    "class ModelBasedReflexVacuumAgent:\n",
    "    \"\"\"\n",
    "    Baseline model-based reflex:\n",
    "    - If current tile is dirty -> SUCK\n",
    "    - Else prefer moving to any UNVISITED neighbor\n",
    "    - Else move randomly among valid moves\n",
    "\n",
    "    Internal model:\n",
    "    - visited set\n",
    "    - knowledge map: unknown / clean\n",
    "    \"\"\"\n",
    "    def __init__(self, seed: int = 0):\n",
    "        self.rnd = random.Random(seed)\n",
    "        self.visited = set()\n",
    "        self.knowledge: Dict[Pos, str] = {}\n",
    "\n",
    "    def update_model(self, percept: Percept) -> None:\n",
    "        self.visited.add(percept.pos)\n",
    "        self.knowledge[percept.pos] = \"CLEAN\" if not percept.dirty_here else \"UNKNOWN\"\n",
    "\n",
    "    def choose_action(self, percept: Percept) -> str:\n",
    "        self.update_model(percept)\n",
    "\n",
    "        if percept.dirty_here:\n",
    "            return \"SUCK\"\n",
    "\n",
    "        r, c = percept.pos\n",
    "        neighbors = []\n",
    "        if not percept.wall_up:    neighbors.append((r - 1, c, \"UP\"))\n",
    "        if not percept.wall_down:  neighbors.append((r + 1, c, \"DOWN\"))\n",
    "        if not percept.wall_left:  neighbors.append((r, c - 1, \"LEFT\"))\n",
    "        if not percept.wall_right: neighbors.append((r, c + 1, \"RIGHT\"))\n",
    "\n",
    "        unvisited_moves = [a for (nr, nc, a) in neighbors if (nr, nc) not in self.visited]\n",
    "        if unvisited_moves:\n",
    "            return self.rnd.choice(unvisited_moves)\n",
    "\n",
    "        valid_moves = [a for (_, _, a) in neighbors]\n",
    "        return self.rnd.choice(valid_moves) if valid_moves else \"NOOP\"\n",
    "\n",
    "def get_percept(room: Room, pos: Pos) -> Percept:\n",
    "    r, c = pos\n",
    "    return Percept(\n",
    "        pos=pos,\n",
    "        dirty_here=room.is_dirty(pos),\n",
    "        wall_up=(r == 0),\n",
    "        wall_down=(r == room.rows - 1),\n",
    "        wall_left=(c == 0),\n",
    "        wall_right=(c == room.cols - 1),\n",
    "    )\n",
    "\n",
    "def step(room: Room, pos: Pos, action: str) -> Pos:\n",
    "    r, c = pos\n",
    "    if action == \"SUCK\":\n",
    "        room.clean(pos)\n",
    "        return pos\n",
    "    if action == \"UP\":    return (r - 1, c) if r > 0 else pos\n",
    "    if action == \"DOWN\":  return (r + 1, c) if r < room.rows - 1 else pos\n",
    "    if action == \"LEFT\":  return (r, c - 1) if c > 0 else pos\n",
    "    if action == \"RIGHT\": return (r, c + 1) if c < room.cols - 1 else pos\n",
    "    return pos\n",
    "\n",
    "def run_episode(\n",
    "    rows: int = 6,\n",
    "    cols: int = 6,\n",
    "    dirt_prob: float = 0.25,\n",
    "    room_seed: int = 1,\n",
    "    agent_seed: int = 1,\n",
    "    max_steps: int = 500,\n",
    "    start: Pos = (0, 0),\n",
    ") -> dict:\n",
    "    room = Room(rows, cols, dirt_prob, seed=room_seed)\n",
    "    agent = ModelBasedReflexVacuumAgent(seed=agent_seed)\n",
    "\n",
    "    pos = start\n",
    "    initial_dirt = room.dirt_count()\n",
    "    steps_taken = 0\n",
    "\n",
    "    while steps_taken < max_steps and room.dirt_count() > 0:\n",
    "        percept = get_percept(room, pos)\n",
    "        action = agent.choose_action(percept)\n",
    "        pos = step(room, pos, action)\n",
    "        steps_taken += 1\n",
    "\n",
    "    return {\n",
    "        \"rows\": rows,\n",
    "        \"cols\": cols,\n",
    "        \"dirt_prob\": dirt_prob,\n",
    "        \"room_seed\": room_seed,\n",
    "        \"agent_seed\": agent_seed,\n",
    "        \"initial_dirt\": initial_dirt,\n",
    "        \"steps_taken\": steps_taken,\n",
    "        \"dirt_remaining\": room.dirt_count(),\n",
    "        \"cleaned_all\": room.dirt_count() == 0,\n",
    "    }\n",
    "\n",
    "def benchmark(trials: int = 30, rows: int = 8, cols: int = 8, dirt_prob: float = 0.30) -> None:\n",
    "    results = []\n",
    "    for t in range(trials):\n",
    "        res = run_episode(rows, cols, dirt_prob, room_seed=1000 + t, agent_seed=42, max_steps=2000)\n",
    "        results.append(res)\n",
    "\n",
    "    steps = [r[\"steps_taken\"] for r in results]\n",
    "    success = sum(1 for r in results if r[\"cleaned_all\"])\n",
    "\n",
    "    print(\"=== Baseline Model-Based Reflex Agent ===\")\n",
    "    print(f\"Trials: {trials}, Grid: {rows}x{cols}, DirtProb: {dirt_prob}\")\n",
    "    print(f\"Success (cleaned all within max_steps): {success}/{trials}\")\n",
    "    print(f\"Avg steps: {statistics.mean(steps):.1f}   Median steps: {statistics.median(steps):.1f}   Min/Max: {min(steps)}/{max(steps)}\")\n",
    "    print(\"\\nYour optimization target: reduce Avg steps and/or increase success rate.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    benchmark()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794f55e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
